{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import car_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建地图\n",
    "car = car_model.KinematicModel()\n",
    "img = np.ones((1000,1000,3))\n",
    "car.init_state((50, 50, 0))\n",
    "# car.update()\n",
    "# img = car.render(img)\n",
    "\n",
    "import random\n",
    "\n",
    "#随机生成18个障碍物\n",
    "get_obstacle_pos = [(random.randint(100, 900), random.randint(100, 900)) for _ in range(18)]  # 障碍物的位置\n",
    "\n",
    "\n",
    "def map_data(input,obstacle):\n",
    "    img = input\n",
    "\n",
    "    obstacle_pos = obstacle\n",
    "    obstacle_size = 50\n",
    "    for pos in obstacle_pos:\n",
    "        top_left = (pos[0] - obstacle_size // 2, pos[1] - obstacle_size // 2)\n",
    "        bottom_right = (pos[0] + obstacle_size // 2, pos[1] + obstacle_size // 2)\n",
    "        cv2.rectangle(img, top_left, bottom_right, (0, 0, 0), -1)  # 用黑色表示障碍物\n",
    "    #生成终点,终点是红框\n",
    "    goal_pos = ((950,950))\n",
    "    goal_size = 50\n",
    "    top_left = (goal_pos[0] - goal_size // 2, goal_pos[1] - goal_size // 2)\n",
    "    bottom_right = (goal_pos[0] + goal_size // 2, goal_pos[1] + goal_size // 2)\n",
    "    cv2.rectangle(img, top_left, bottom_right, (0, 0, 255), 2)  # 用红色表示终点\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LidarModel:   #雷达模型\n",
    "    def __init__(self,\n",
    "            img_map,\n",
    "            sensor_size = 21,\n",
    "            start_angle = -120.0,\n",
    "            end_angle = 120.0,\n",
    "            max_dist = 200.0):\n",
    "        self.sensor_size = sensor_size  #传感器大小\n",
    "        self.start_angle = start_angle  #开始角度\n",
    "        self.end_angle = end_angle  #结束角度\n",
    "        self.max_dist = max_dist    #最大距离\n",
    "        self.img_map = img_map  #图像地图\n",
    "    \n",
    "    def measure(self, pos): #测量\n",
    "        sense_data = []\n",
    "        inter = (self.end_angle-self.start_angle) / (self.sensor_size-1)    #间隔\n",
    "        for i in range(self.sensor_size):\n",
    "            theta = pos[2] + self.start_angle + i*inter\n",
    "            sense_data.append(self._ray_cast(np.array((pos[0], pos[1])), theta))\n",
    "        # print(sense_data)\n",
    "        return sense_data\n",
    "\n",
    "\n",
    "    def _ray_cast(self, pos, theta):  #射线\n",
    "        x = pos[0]\n",
    "        y = pos[1]\n",
    "        while np.sqrt((x-pos[0])**2 + (y-pos[1])**2) < self.max_dist:\n",
    "            if x < 0 or y < 0 or x >= self.img_map.shape[1] or y >= self.img_map.shape[0]:\n",
    "                return self.max_dist\n",
    "            \n",
    "            if self.img_map[int(y), int(x)].all() == 0:\n",
    "                return np.sqrt((x-pos[0])**2 + (y-pos[1])**2)\n",
    "            x += np.cos(np.deg2rad(theta))  \n",
    "            y += np.sin(np.deg2rad(theta))\n",
    "        return self.max_dist\n",
    "    \n",
    "    # def render(self, pos):  #渲染\n",
    "    #     img = self.img_map.copy()\n",
    "    #     sense_data = self.measure(pos)\n",
    "    #     # print(sense_data)\n",
    "    #     for i, dist in enumerate(sense_data):\n",
    "    #         theta = pos[2] + self.start_angle + i*(self.end_angle-self.start_angle) / (self.sensor_size-1)\n",
    "    #         x = pos[0] + dist*np.cos(np.deg2rad(theta))\n",
    "    #         y = pos[1] + dist*np.sin(np.deg2rad(theta))\n",
    "    #         cv2.line(img, (int(pos[0]), int(pos[1])), (int(x), int(y)), (255, 0, 0), 1)\n",
    "    #     return img\n",
    "\n",
    "lidar = LidarModel(img)\n",
    "# while True:\n",
    "#     print(\n",
    "#         \"\\rx={}, y={}, v={}, yaw={}, w={}\".format(str(car.x)[:5], str(car.y)[:5], str(car.v)[:5], str(car.yaw)[:5],\n",
    "#                                                   str(car.w)[:5]), end=\"\\t\")\n",
    "#     car.update()\n",
    "#     img = map_data(img,get_obstacle_pos)\n",
    "#     img = lidar.render((car.x, car.y, car.yaw))\n",
    "#     img = car.render(img)\n",
    "#     img = cv2.flip(img, 0)\n",
    "#     cv2.imshow(\"demo\", img)\n",
    "#     k = cv2.waitKey(1)\n",
    "#     if k == ord(\"a\"):\n",
    "#         car.w += 5\n",
    "#     elif k == ord(\"d\"):\n",
    "#         car.w -= 5\n",
    "#     elif k == ord(\"w\"):\n",
    "#         car.v += 4\n",
    "#     elif k == ord(\"s\"):\n",
    "#         car.v -= 4\n",
    "#     elif k == ord(\"q\"):\n",
    "#         print()\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=53.59, y=50.02, v=12, yaw=1.675, w=0\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrxiuer/.conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=138.0, y=140.4, v=12, yaw=49.15, w=0\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m img \u001b[38;5;241m=\u001b[39m map_data(img,get_obstacle_pos)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# img = lidar.render((car.x, car.y, car.yaw))\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m img \u001b[38;5;241m=\u001b[39m car\u001b[38;5;241m.\u001b[39mrender(img)\n\u001b[1;32m     74\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(img, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[65], line 30\u001b[0m, in \u001b[0;36mtarget_point.render\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m,pos):   \u001b[38;5;66;03m#渲染,最短为紫色，其他为绿色\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 30\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_target_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m950\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m950\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lidar\u001b[38;5;241m.\u001b[39msensor_size):\n\u001b[1;32m     32\u001b[0m         theta \u001b[38;5;241m=\u001b[39m pos[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlidar\u001b[38;5;241m.\u001b[39mstart_angle \u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlidar\u001b[38;5;241m.\u001b[39mend_angle\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlidar\u001b[38;5;241m.\u001b[39mstart_angle) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlidar\u001b[38;5;241m.\u001b[39msensor_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[65], line 18\u001b[0m, in \u001b[0;36mtarget_point.get_target_point\u001b[0;34m(self, start_pos, end_pos)\u001b[0m\n\u001b[1;32m     16\u001b[0m theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     17\u001b[0m f \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#获取雷达射线端点到达终点最小距离的索引\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lidar\u001b[38;5;241m.\u001b[39msensor_size):\n",
      "Cell \u001b[0;32mIn[65], line 13\u001b[0m, in \u001b[0;36mtarget_point.messure\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessure\u001b[39m(\u001b[38;5;28mself\u001b[39m,pos):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlidar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[64], line 19\u001b[0m, in \u001b[0;36mLidarModel.measure\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msensor_size):\n\u001b[1;32m     18\u001b[0m     theta \u001b[38;5;241m=\u001b[39m pos[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_angle \u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m*\u001b[39minter\n\u001b[0;32m---> 19\u001b[0m     sense_data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ray_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(sense_data)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sense_data\n",
      "Cell \u001b[0;32mIn[64], line 31\u001b[0m, in \u001b[0;36mLidarModel._ray_cast\u001b[0;34m(self, pos, theta)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_map\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m y \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_map\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_dist\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqrt((x\u001b[38;5;241m-\u001b[39mpos[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (y\u001b[38;5;241m-\u001b[39mpos[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(np\u001b[38;5;241m.\u001b[39mdeg2rad(theta))  \n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.9/site-packages/numpy/core/_methods.py:64\u001b[0m, in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#使用雷达数据，选择雷达数据中到达终点最小距离的参数，作为目标点，\n",
    "\n",
    "class target_point:\n",
    "    def __init__(self,img,lidar):\n",
    "        self.lidar = lidar\n",
    "        self.img = img\n",
    "        self.dist = []\n",
    "\n",
    "    def distance(self,pos1,pos2):\n",
    "        return np.sqrt((pos1[0]-pos2[0])**2 + (pos1[1]-pos2[1])**2)\n",
    "    \n",
    "    def messure(self,pos):\n",
    "        self.dist = self.lidar.measure(pos)\n",
    "\n",
    "    def get_target_point(self,start_pos,end_pos):\n",
    "        theta = 0\n",
    "        f = []\n",
    "        self.messure(start_pos)\n",
    "        #获取雷达射线端点到达终点最小距离的索引\n",
    "        for i in range(lidar.sensor_size):\n",
    "            theta = start_pos[2] + self.lidar.start_angle + i*(self.lidar.end_angle-self.lidar.start_angle) / (self.lidar.sensor_size-1)\n",
    "            x = start_pos[0] + self.dist[i]*np.cos(np.deg2rad(theta))\n",
    "            y = start_pos[1] + self.dist[i]*np.sin(np.deg2rad(theta))\n",
    "            f.append(self.distance((x,y),end_pos))\n",
    "        #返回大于30的最小值索引,防止碰撞\n",
    "        return f.index(min([i for i in f if i > 30]))\n",
    "    \n",
    "    def render(self,pos):   #渲染,最短为紫色，其他为绿色\n",
    "        img = self.img.copy()\n",
    "        target = self.get_target_point(pos,(950,950))\n",
    "        for i in range(lidar.sensor_size):\n",
    "            theta = pos[2] + self.lidar.start_angle + i*(self.lidar.end_angle-self.lidar.start_angle) / (self.lidar.sensor_size-1)\n",
    "            x = pos[0] + self.dist[i]*np.cos(np.deg2rad(theta))\n",
    "            y = pos[1] + self.dist[i]*np.sin(np.deg2rad(theta))\n",
    "            if i == target:\n",
    "                cv2.line(img, (int(pos[0]), int(pos[1])), (int(x), int(y)), (255, 0, 255), 1)\n",
    "            else:\n",
    "                cv2.line(img, (int(pos[0]), int(pos[1])), (int(x), int(y)), (0, 255, 0), 1)\n",
    "        return img\n",
    "    \n",
    "target = target_point(img,lidar)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#使用RNN模型，输入为雷达最小距离的theta和小车的方向角，输出为角度\n",
    "#指定小车的厨师速度为12\n",
    "car.v = 12\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=2, hidden_size=20, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(20, 1)\n",
    "    \n",
    "    def forward(self, x,h_state):\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        out = self.fc(r_out[:, -1, :])\n",
    "        return out,h_state\n",
    "\n",
    "h_state = None\n",
    "rnn = RNN().to(device)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)\n",
    "\n",
    "while True:\n",
    "    print(\n",
    "        \"\\rx={}, y={}, v={}, yaw={}, w={}\".format(str(car.x)[:5], str(car.y)[:5], str(car.v)[:5], str(car.yaw)[:5],\n",
    "                                                  str(car.w)[:5]), end=\"\\t\")\n",
    "    car.update()\n",
    "    img = map_data(img,get_obstacle_pos)\n",
    "    # img = lidar.render((car.x, car.y, car.yaw))\n",
    "    img = target.render((car.x, car.y, car.yaw))\n",
    "    img = car.render(img)\n",
    "    img = cv2.flip(img, 0)\n",
    "    cv2.imshow(\"demo\", img)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord(\"w\"):\n",
    "        car.v += 4\n",
    "    elif k == ord(\"s\"):\n",
    "        car.v -= 4\n",
    "    elif k == ord(\"q\"):\n",
    "        print()\n",
    "        break\n",
    "    else:\n",
    "        f = target.get_target_point((car.x,car.y,car.yaw),(950,950))\n",
    "        theta = lidar.start_angle + f*(lidar.end_angle-lidar.start_angle) / (lidar.sensor_size-1)\n",
    "        x = np.array([theta,car.yaw])\n",
    "        x = torch.from_numpy(x).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "        out , _ = rnn(x,h_state)\n",
    "        car.yaw += out.item()\n",
    "        loss_func = loss(out,torch.tensor(theta).to(device))\n",
    "        # print(out)\n",
    "        optimizer.zero_grad()\n",
    "        loss_func.backward()\n",
    "        optimizer.step()\n",
    "cv2.destroyAllWindows()\n",
    "# while True:\n",
    "#     print(\n",
    "#         \"\\rx={}, y={}, v={}, yaw={}, w={}\".format(str(car.x)[:5], str(car.y)[:5], str(car.v)[:5], str(car.yaw)[:5],\n",
    "#                                                   str(car.w)[:5]), end=\"\\t\")\n",
    "#     car.update()\n",
    "#     img = map_data(img,get_obstacle_pos)\n",
    "#     # img = lidar.render((car.x, car.y, car.yaw))\n",
    "#     img = target.render((car.x, car.y, car.yaw))\n",
    "#     img = car.render(img)\n",
    "#     img = cv2.flip(img, 0)\n",
    "#     cv2.imshow(\"demo\", img)\n",
    "#     k = cv2.waitKey(2)\n",
    "#     if k == ord(\"a\"):\n",
    "#         car.w += 5\n",
    "#     elif k == ord(\"d\"):\n",
    "#         car.w -= 5\n",
    "#     elif k == ord(\"w\"):\n",
    "#         car.v += 4\n",
    "#     elif k == ord(\"s\"):\n",
    "#         car.v -= 4\n",
    "#     elif k == ord(\"q\"):\n",
    "#         print()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
